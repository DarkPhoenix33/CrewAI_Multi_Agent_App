
import streamlit as st
from crewai import Crew, Process, Agent, Task
from langchain_openai import ChatOpenAI
import os
from dotenv import load_dotenv
import io
import sys
from langchain_core.callbacks import BaseCallbackHandler
from langchain_core.outputs import LLMResult

# Load environment variables
load_dotenv()

# Set OpenAI API key
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# Import PowerShellExecutor
from src.tools.powershell_executor import PowerShellExecutor

# Custom Callback Handler for Token Counting
class TokenCountingCallbackHandler(BaseCallbackHandler):
    def __init__(self):
        self.input_tokens = 0
        self.output_tokens = 0

    def on_llm_end(self, response: LLMResult, **kwargs) -> None:
        # Prioritize response.usage for OpenAI models
        if hasattr(response, 'usage') and response.usage:
            self.input_tokens += response.usage.prompt_tokens
            self.output_tokens += response.usage.completion_tokens
        elif response.llm_output and "token_usage" in response.llm_output:
            token_usage = response.llm_output["token_usage"]
            if "prompt_tokens" in token_usage:
                self.input_tokens += token_usage["prompt_tokens"]
            if "completion_tokens" in token_usage:
                self.output_tokens += token_usage["completion_tokens"]

# Initialize the PowerShellExecutor using st.cache_resource
@st.cache_resource
def get_powershell_executor():
    return PowerShellExecutor()

powershell_tool = get_powershell_executor()

# Define Agents (copied from src/main.py, now using the cached powershell_tool)
iis_manager = Agent(
    role='IIS Manager',
    goal='Efficiently manage IIS web servers, application pools, and websites using precise PowerShell commands, specifically prioritizing `Get-ChildItem IIS:\\AppPools` for listing application pools and ensuring accurate, raw data retrieval.',
    backstory='An expert in Microsoft IIS, capable of configuring, monitoring, and troubleshooting IIS environments with a focus on optimal PowerShell command usage and providing precise, raw output for all queries.',
    verbose=True,
    allow_delegation=True,
    tools=[powershell_tool]
)

powershell_script_developer = Agent(
    role='PowerShell Script Developer',
    goal='Create highly efficient, robust, and reusable PowerShell script files, and manage file operations (read, write, append) ensuring correct formatting and saving of content as requested.',
    backstory='A seasoned PowerShell scripter with a deep understanding of Windows automation, best practices, and meticulous file handling for script creation and data storage.',
    verbose=True,
    allow_delegation=True,
    tools=[powershell_tool]
)

task_scheduler_agent = Agent(
    role='Task Scheduler Agent',
    goal='Automate tasks by creating, modifying, and managing scheduled tasks in Windows Task Scheduler with precise trigger settings and administrative privileges.',
    backstory='Proficient in Windows Task Scheduler, ensuring timely and secure execution of automated scripts and commands with the necessary permissions.',
    verbose=True,
    allow_delegation=True,
    tools=[powershell_tool]
)

windows_service_manager = Agent(
    role='Windows Service Manager',
    goal='Manage Windows services, including starting, stopping, restarting, and configuring them.',
    backstory='An expert in Windows service administration, ensuring system stability and application availability.',
    verbose=True,
    allow_delegation=True,
    tools=[powershell_tool]
)

log_event_manager = Agent(
    role='Log and Event Manager',
    goal='Monitor, analyze, and manage Windows event logs and application logs for troubleshooting and security.',
    backstory='A specialist in log analysis, capable of extracting critical information from Windows event logs and various application logs.',
    verbose=True,
    allow_delegation=True,
    tools=[powershell_tool]
)

# Define main_task (copied from src/main.py)
main_task = Task(
    description=(
        r"Analyze the user's request and break it down into sub-tasks if necessary. "
        r"Delegate these sub-tasks to the appropriate specialized agents (IIS Manager, PowerShell Script Developer, "
        r"Task Scheduler Agent, Windows Service Manager, Log and Event Manager). "
        r"Ensure that all necessary information (e.g., script content, file paths, frequencies) is gathered "
        r"from the user or generated by the agents as needed. If the request involves saving output to a file, "
        r"ensure the file is created/updated correctly with the specified content and format. "
        r"For tasks involving IIS Application Pools, ALWAYS use `Get-ChildItem IIS:\AppPools | Select-Object Name, State` to list them, and then filter/select properties as needed. "
        r"NEVER use `Get-WebAppPoolState` for listing application pools. "
        r"The final output MUST be the raw, uninterpreted result of the executed command (formatted as a table or JSON by the agent itself), or a clear confirmation of the action taken. "
        r"If a task fails, the manager should attempt to retry or re-plan the approach. "
        r"User Request: {user_request}"
    ),
    expected_output=(
        r"The raw, uninterpreted output of the executed PowerShell command (formatted as a table or JSON). "
        r"If the request involved an action (e.g., script creation, task scheduling), provide a clear, concise confirmation (e.g., 'Script created at C:\path\to\script.ps1', 'Task scheduled successfully'). "
        r"If an error occurred, provide the exact error message without interpretation."
    ),
    agent=None  # This task will be handled by the manager agent implicitly
)


# Initialize the LLM for the manager agent
manager_llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0) # Changed to gpt-3.5-turbo

st.set_page_config(page_title="Multi-Agent PowerShell System", page_icon=":robot:")

st.title("Multi-Agent PowerShell System")
st.markdown("Interact with the PowerShell agents to manage your Windows environment.")

# Initialize session state for token counts
if "total_input_tokens" not in st.session_state:
    st.session_state.total_input_tokens = 0
if "total_output_tokens" not in st.session_state:
    st.session_state.total_output_tokens = 0

# Sidebar for controls
with st.sidebar:
    st.header("Controls")
    if st.button("Clear Chat"):
        st.session_state.messages = []
        st.session_state.detailed_logs = ""
        st.session_state.total_input_tokens = 0
        st.session_state.total_output_tokens = 0
        st.rerun()

    show_detailed_logs = st.checkbox("Show detailed logs", value=False)

    st.markdown("---")
    st.subheader("Token Usage (Current Session)")
    st.write(f"Input Tokens: {st.session_state.total_input_tokens}")
    st.write(f"Output Tokens: {st.session_state.total_output_tokens}")

# Initialize chat history and detailed logs in session state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "detailed_logs" not in st.session_state:
    st.session_state.detailed_logs = ""

# Display chat messages from history on app rerun
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# React to user input
if prompt := st.chat_input("What do you want to do?"):
    # Display user message in chat message container
    st.chat_message("user").markdown(prompt)
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": prompt})

    # Initialize callback handler for this request
    token_callback_handler = TokenCountingCallbackHandler()
    
    # Re-initialize manager_llm with the callback handler for each request
    # This ensures token counts are specific to the current interaction
    current_manager_llm = ChatOpenAI(
        model_name="gpt-3.5-turbo", # Ensure this is gpt-3.5-turbo
        temperature=0, 
        callbacks=[token_callback_handler]
    )

    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            try:
                # Capture stdout if detailed logs are requested
                if show_detailed_logs:
                    old_stdout = sys.stdout
                    sys.stdout = captured_output = io.StringIO()
                    st.info("Processing... Detailed logs will appear below after the agent completes its task.")

                crew = Crew(
                    agents=[
                        iis_manager,
                        powershell_script_developer,
                        task_scheduler_agent,
                        windows_service_manager,
                        log_event_manager
                    ],
                    tasks=[main_task],
                    verbose=True,  # Always verbose to capture logs
                    process=Process.hierarchical,
                    manager_llm=current_manager_llm # Use the LLM with callback handler
                )

                # Kick off the crew with the user's request
                result = crew.kickoff(inputs={"user_request": prompt})

                # Restore stdout
                if show_detailed_logs:
                    sys.stdout = old_stdout
                    st.session_state.detailed_logs = captured_output.getvalue()

                st.markdown(result)
                st.session_state.messages.append({"role": "assistant", "content": result})

                # Update total token counts
                st.session_state.total_input_tokens += token_callback_handler.input_tokens
                st.session_state.total_output_tokens += token_callback_handler.output_tokens

            except Exception as e:
                error_message = f"An error occurred: {e}"
                st.error(error_message)
                st.session_state.messages.append({"role": "assistant", "content": error_message})
            finally:
                # Ensure stdout is restored even if an error occurs
                if show_detailed_logs and sys.stdout != old_stdout:
                    sys.stdout = old_stdout

# Display detailed logs if enabled and available
if show_detailed_logs and st.session_state.detailed_logs:
    with st.expander("Detailed Agent Logs"):
        st.code(st.session_session.detailed_logs, language="bash")
